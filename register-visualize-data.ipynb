{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register and visualize dataset\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this lab you will ingest and transform the customer product reviews dataset. Then you will use AWS data stack services such as AWS Glue and Amazon Athena for ingesting and querying the dataset. Finally you will use AWS Data Wrangler to analyze the dataset and plot some visuals extracting insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "- [1. Ingest and transform the public dataset](#c1w1-1.)\n",
    "  - [1.1. List the dataset files in the public S3 bucket](#c1w1-1.1.)\n",
    "    - [Exercise 1](#c1w1-ex-1)\n",
    "  - [1.2. Copy the data locally to the notebook](#c1w1-1.2.)\n",
    "  - [1.3. Transform the data](#c1w1-1.3.)\n",
    "  - [1.4 Write the data to a CSV file](#c1w1-1.4.)\n",
    "- [2. Register the public dataset for querying and visualizing](#c1w1-2.)\n",
    "  - [2.1. Register S3 dataset files as a table for querying](#c1w1-2.1.)\n",
    "    - [Exercise 2](#c1w1-ex-2)\n",
    "  - [2.2. Create default S3 bucket for Amazon Athena](#c1w1-2.2.)\n",
    "- [3. Visualize data](#c1w1-3.)\n",
    "  - [3.1. Preparation for data visualization](#c1w1-3.1.)\n",
    "  - [3.2. How many reviews per sentiment?](#c1w1-3.2.)\n",
    "    - [Exercise 3](#c1w1-ex-3)\n",
    "  - [3.3. Which product categories are highest rated by average sentiment?](#c1w1-3.3.)\n",
    "  - [3.4. Which product categories have the most reviews?](#c1w1-3.4.)\n",
    "    - [Exercise 4](#c1w1-ex-4)\n",
    "  - [3.5. What is the breakdown of sentiments per product category?](#c1w1-3.5.)\n",
    "  - [3.6. Analyze the distribution of review word counts](#c1w1-3.6.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install the required modules first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "sagemaker-data-insights 0.3.3 requires numpy>=1.21.6, but you have numpy 1.20.3 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\n",
      "spyder 4.0.1 requires jedi==0.14.1, but you have jedi 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "sagemaker-data-insights 0.3.3 requires numpy>=1.21.6, but you have numpy 1.18.5 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!pip install --disable-pip-version-check -q pandas==1.1.4\n",
    "!pip install --disable-pip-version-check -q awswrangler==2.7.0\n",
    "!pip install --disable-pip-version-check -q numpy==1.18.5\n",
    "!pip install --disable-pip-version-check -q seaborn==0.11.0\n",
    "!pip install --disable-pip-version-check -q matplotlib===3.3.3\n",
    "!pip install -q protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-1.'></a>\n",
    "# 1. Ingest and transform the public dataset\n",
    "\n",
    "The dataset [Women's Clothing Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) has been chosen as the main dataset.\n",
    "\n",
    "It is shared in a public Amazon S3 bucket, and is available as a comma-separated value (CSV) text format:\n",
    "\n",
    "`s3://dlai-practical-data-science/data/raw/womens_clothing_ecommerce_reviews.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-1.1.'></a>\n",
    "### 1.1. List the dataset files in the public S3 bucket\n",
    "\n",
    "The [AWS Command Line Interface (CLI)](https://awscli.amazonaws.com/v2/documentation/api/latest/index.html) is a unified tool to manage your AWS services. With just one tool, you can control multiple AWS services from the command line and automate them through scripts. You will use it to list the dataset files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View dataset files in CSV format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```aws s3 ls [bucket_name]``` function lists all objects in the S3 bucket. Let's use it to view the reviews data files in CSV format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-ex-1'></a>\n",
    "### Exercise 1\n",
    "\n",
    "View the list of the files available in the public bucket `s3://dlai-practical-data-science/data/raw/`.\n",
    "\n",
    "**Instructions**:\n",
    "Use `aws s3 ls [bucket_name]` function. To run the AWS CLI command from the notebook you will need to put an exclamation mark in front of it: `!aws`. You should see the data file `womens_clothing_ecommerce_reviews.csv` in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-30 02:21:06    8457214 womens_clothing_ecommerce_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "!aws s3 ls s3://dlai-practical-data-science/data/raw/\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# ... womens_clothing_ecommerce_reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-1.2.'></a>\n",
    "### 1.2. Copy the data locally to the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```aws s3 cp [bucket_name/file_name] [file_name]``` function copies the file from the S3 bucket into the local environment or into another S3 bucket. Let's use it to copy the file with the dataset locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dlai-practical-data-science/data/raw/womens_clothing_ecommerce_reviews.csv to ./womens_clothing_ecommerce_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://dlai-practical-data-science/data/raw/womens_clothing_ecommerce_reviews.csv ./womens_clothing_ecommerce_reviews.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the Pandas dataframe to load and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv('./womens_clothing_ecommerce_reviews.csv',\n",
    "                 index_col=0)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>847</td>\n",
       "      <td>33</td>\n",
       "      <td>Cute, crisp shirt</td>\n",
       "      <td>If this product was in petite  i would get the...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love  love  love this jumpsuit. it's fun  fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>1104</td>\n",
       "      <td>34</td>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>862</td>\n",
       "      <td>48</td>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft  stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>1104</td>\n",
       "      <td>31</td>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well  but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>1084</td>\n",
       "      <td>28</td>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>1104</td>\n",
       "      <td>52</td>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23486 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clothing ID  Age                                              Title  \\\n",
       "0              847   33                                  Cute, crisp shirt   \n",
       "1             1080   34                                                NaN   \n",
       "2             1077   60                            Some major design flaws   \n",
       "3             1049   50                                   My favorite buy!   \n",
       "4              847   47                                   Flattering shirt   \n",
       "...            ...  ...                                                ...   \n",
       "23481         1104   34                     Great dress for many occasions   \n",
       "23482          862   48                         Wish it was made of cotton   \n",
       "23483         1104   31                              Cute, but see through   \n",
       "23484         1084   28  Very cute dress, perfect for summer parties an...   \n",
       "23485         1104   52                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "0      If this product was in petite  i would get the...       4   \n",
       "1      Love this dress!  it's sooo pretty.  i happene...       5   \n",
       "2      I had such high hopes for this dress and reall...       3   \n",
       "3      I love  love  love this jumpsuit. it's fun  fl...       5   \n",
       "4      This shirt is very flattering to all due to th...       5   \n",
       "...                                                  ...     ...   \n",
       "23481  I was very happy to snag this dress at such a ...       5   \n",
       "23482  It reminds me of maternity clothes. soft  stre...       3   \n",
       "23483  This fit well  but the top was very see throug...       3   \n",
       "23484  I bought this dress for a wedding i have this ...       3   \n",
       "23485  This dress in a lovely platinum is feminine an...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0                    1                        2         General   \n",
       "1                    1                        4         General   \n",
       "2                    0                        0         General   \n",
       "3                    1                        0  General Petite   \n",
       "4                    1                        6         General   \n",
       "...                ...                      ...             ...   \n",
       "23481                1                        0  General Petite   \n",
       "23482                1                        0  General Petite   \n",
       "23483                0                        1  General Petite   \n",
       "23484                1                        2         General   \n",
       "23485                1                       22  General Petite   \n",
       "\n",
       "      Department Name Class Name  \n",
       "0                Tops    Blouses  \n",
       "1             Dresses    Dresses  \n",
       "2             Dresses    Dresses  \n",
       "3             Bottoms      Pants  \n",
       "4                Tops    Blouses  \n",
       "...               ...        ...  \n",
       "23481         Dresses    Dresses  \n",
       "23482            Tops      Knits  \n",
       "23483         Dresses    Dresses  \n",
       "23484         Dresses    Dresses  \n",
       "23485         Dresses    Dresses  \n",
       "\n",
       "[23486 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-1.3.'></a>\n",
    "### 1.3. Transform the data\n",
    "To simplify the task, you will transform the data into a comma-separated value (CSV) file that contains only a `review_body`, `product_category`, and `sentiment` derived from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22628, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = df.rename(columns={'Review Text': 'review_body',\n",
    "                                    'Rating': 'star_rating',\n",
    "                                    'Class Name': 'product_category'})\n",
    "df_transformed.drop(columns=['Clothing ID', 'Age', 'Title', 'Recommended IND', 'Positive Feedback Count', 'Division Name', 'Department Name'],\n",
    "                    inplace=True)\n",
    "\n",
    "df_transformed.dropna(inplace=True)\n",
    "\n",
    "df_transformed.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If this product was in petite  i would get the...</td>\n",
       "      <td>4</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love  love  love this jumpsuit. it's fun  fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>It reminds me of maternity clothes. soft  stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>This fit well  but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22628 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_body  star_rating  \\\n",
       "0      If this product was in petite  i would get the...            4   \n",
       "1      Love this dress!  it's sooo pretty.  i happene...            5   \n",
       "2      I had such high hopes for this dress and reall...            3   \n",
       "3      I love  love  love this jumpsuit. it's fun  fl...            5   \n",
       "4      This shirt is very flattering to all due to th...            5   \n",
       "...                                                  ...          ...   \n",
       "23481  I was very happy to snag this dress at such a ...            5   \n",
       "23482  It reminds me of maternity clothes. soft  stre...            3   \n",
       "23483  This fit well  but the top was very see throug...            3   \n",
       "23484  I bought this dress for a wedding i have this ...            3   \n",
       "23485  This dress in a lovely platinum is feminine an...            5   \n",
       "\n",
       "      product_category  \n",
       "0              Blouses  \n",
       "1              Dresses  \n",
       "2              Dresses  \n",
       "3                Pants  \n",
       "4              Blouses  \n",
       "...                ...  \n",
       "23481          Dresses  \n",
       "23482            Knits  \n",
       "23483          Dresses  \n",
       "23484          Dresses  \n",
       "23485          Dresses  \n",
       "\n",
       "[22628 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert the `star_rating` into the `sentiment` (positive, neutral, negative), which later on will be for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22626, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_sentiment(star_rating):\n",
    "    if star_rating in {1, 2}: # negative\n",
    "        return -1 \n",
    "    if star_rating == 3:      # neutral\n",
    "        return 0\n",
    "    if star_rating in {4, 5}: # positive\n",
    "        return 1\n",
    "\n",
    "# transform star_rating into the sentiment\n",
    "df_transformed['sentiment'] = df_transformed['star_rating'].apply(lambda star_rating: \n",
    "    to_sentiment(star_rating=star_rating) \n",
    ")\n",
    "\n",
    "# drop the star rating column\n",
    "df_transformed.drop(columns=['star_rating'],\n",
    "                    inplace=True)\n",
    "\n",
    "# remove reviews for product_categories with < 10 reviews\n",
    "df_transformed = df_transformed.groupby('product_category').filter(lambda reviews : len(reviews) > 10)[['sentiment', 'review_body', 'product_category']]\n",
    "\n",
    "df_transformed.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_body</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>If this product was in petite  i would get the...</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I love  love  love this jumpsuit. it's fun  fl...</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>1</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>0</td>\n",
       "      <td>It reminds me of maternity clothes. soft  stre...</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>0</td>\n",
       "      <td>This fit well  but the top was very see throug...</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>0</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>1</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22626 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                        review_body  \\\n",
       "0              1  If this product was in petite  i would get the...   \n",
       "1              1  Love this dress!  it's sooo pretty.  i happene...   \n",
       "2              0  I had such high hopes for this dress and reall...   \n",
       "3              1  I love  love  love this jumpsuit. it's fun  fl...   \n",
       "4              1  This shirt is very flattering to all due to th...   \n",
       "...          ...                                                ...   \n",
       "23481          1  I was very happy to snag this dress at such a ...   \n",
       "23482          0  It reminds me of maternity clothes. soft  stre...   \n",
       "23483          0  This fit well  but the top was very see throug...   \n",
       "23484          0  I bought this dress for a wedding i have this ...   \n",
       "23485          1  This dress in a lovely platinum is feminine an...   \n",
       "\n",
       "      product_category  \n",
       "0              Blouses  \n",
       "1              Dresses  \n",
       "2              Dresses  \n",
       "3                Pants  \n",
       "4              Blouses  \n",
       "...                ...  \n",
       "23481          Dresses  \n",
       "23482            Knits  \n",
       "23483          Dresses  \n",
       "23484          Dresses  \n",
       "23485          Dresses  \n",
       "\n",
       "[22626 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the results\n",
    "df_transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-1.4.'></a>\n",
    "### 1.4 Write the data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_transformed.to_csv('./womens_clothing_ecommerce_reviews_transformed.csv', \n",
    "                      index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment,review_body,product_category\n",
      "1,If this product was in petite  i would get the petite. the regular is a little long on me but a tailor can do a simple fix on that.     fits nicely! i'm 5'4  130lb and pregnant so i bough t medium to grow into.     the tie can be front or back so provides for some nice flexibility on form fitting.,Blouses\n",
      "1,\"Love this dress!  it's sooo pretty.  i happened to find it in a store  and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\"\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\",Dresses\n",
      "0,I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium  which was just ok. overall  the top half was comfortable and fit nicely  but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo  a major design flaw was the net over layer sewn directly into the zipper - it c,Dresses\n",
      "1,I love  love  love this jumpsuit. it's fun  flirty  and fabulous! every time i wear it  i get nothing but great compliments!,Pants\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./womens_clothing_ecommerce_reviews_transformed.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-2.'></a>\n",
    "# 2. Register the public dataset for querying and visualizing\n",
    "You will register the public dataset into an S3-backed database table so you can query and visualize our dataset at scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-2.1.'></a>\n",
    "### 2.1. Register S3 dataset files as a table for querying\n",
    "Let's import required modules.\n",
    "\n",
    "`boto3` is the AWS SDK for Python to create, configure, and manage AWS services, such as Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Simple Storage Service (Amazon S3). The SDK provides an object-oriented API as well as low-level access to AWS services. \n",
    "\n",
    "`sagemaker` is the SageMaker Python SDK which provides several high-level abstractions for working with the Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket: sagemaker-us-east-1-676800271250\n",
      "Region: us-east-1\n",
      "Account ID: <bound method Session.account_id of <sagemaker.session.Session object at 0x7f8185fa6410>>\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import botocore\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c1/w1')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm)                         \n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "account_id = sess.account_id\n",
    "\n",
    "print('S3 Bucket: {}'.format(bucket))\n",
    "print('Region: {}'.format(region))\n",
    "print('Account ID: {}'.format(account_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the empty bucket which was created automatically for this account.\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- click on the S3 bucket name `sagemaker-us-east-1-ACCOUNT`\n",
    "- check that it is empty at this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/home?region=us-east-1#\">Amazon S3 buckets</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/home?region={}#\">Amazon S3 buckets</a></b>'.format(region)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the file into the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./womens_clothing_ecommerce_reviews_transformed.csv to s3://sagemaker-us-east-1-676800271250/data/transformed/womens_clothing_ecommerce_reviews_transformed.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./womens_clothing_ecommerce_reviews_transformed.csv s3://$bucket/data/transformed/womens_clothing_ecommerce_reviews_transformed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the bucket with the file we uploaded above.\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- check that the CSV file is located in the S3 bucket\n",
    "- check the location directory structure is the same as in the CLI command above\n",
    "- click on the file name and see the available information about the file (region, size, S3 URI, Amazon Resource Name (ARN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-676800271250?region=us-east-1&prefix=data/transformed/#\">Amazon S3 buckets</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?region={}&prefix=data/transformed/#\">Amazon S3 buckets</a></b>'.format(bucket, region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import AWS Data Wrangler**\n",
    "\n",
    "[AWS Data Wrangler](https://github.com/awslabs/aws-data-wrangler) is an AWS Professional Service open source python initiative that extends the power of Pandas library to AWS connecting dataframes and AWS data related services (Amazon Redshift, AWS Glue, Amazon Athena, Amazon EMR, Amazon QuickSight, etc).\n",
    "\n",
    "Built on top of other open-source projects like Pandas, Apache Arrow, Boto3, SQLAlchemy, Psycopg2 and PyMySQL, it offers abstracted functions to execute usual ETL tasks like load/unload data from data lakes, data warehouses and databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the AWS Data Wrangler documentation: https://aws-data-wrangler.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create AWS Glue Catalog database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data catalog features of **AWS Glue** and the inbuilt integration to Amazon S3 simplify the process of identifying data and deriving the schema definition out of the discovered data. Using AWS Glue crawlers within your data catalog, you can traverse your data stored in Amazon S3 and build out the metadata tables that are defined in your data catalog.\n",
    "\n",
    "Here you will use `wr.catalog.create_database` function to create a database with the name `dsoaws_deep_learning` (\"dsoaws\" stands for \"Data Science on AWS\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.catalog.create_database(\n",
    "    name='dsoaws_deep_learning',\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = wr.catalog.get_databases()\n",
    "\n",
    "for db in dbs:\n",
    "    print(\"Database name: \" + db['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the created database in the AWS Glue Catalog.\n",
    "\n",
    "**Instructions**:\n",
    "- open the link\n",
    "- on the left side panel notice that you are in the AWS Glue -> Data Catalog -> Databases\n",
    "- check that the database `dsoaws_deep_learning` has been created\n",
    "- click on the name of the database\n",
    "- click on the `Tables in dsoaws_deep_learning` link to see that there are no tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"top\" href=\"https://console.aws.amazon.com/glue/home?region={}#catalog:tab=databases\">AWS Glue Databases</a></b>'.format(region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Register CSV data with AWS Glue Catalog**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-ex-2'></a>\n",
    "### Exercise 2\n",
    "\n",
    "Register CSV data with AWS Glue Catalog.\n",
    "\n",
    "**Instructions**:\n",
    "Use ```wr.catalog.create_csv_table``` function with the following parameters\n",
    "```python\n",
    "res = wr.catalog.create_csv_table(\n",
    "    database='...', # AWS Glue Catalog database name\n",
    "    path='s3://{}/data/transformed/'.format(bucket), # S3 object path for the data\n",
    "    table='reviews', # registered table name\n",
    "    columns_types={\n",
    "        'sentiment': 'int',        \n",
    "        'review_body': 'string',\n",
    "        'product_category': 'string'      \n",
    "    },\n",
    "    mode='overwrite',\n",
    "    skip_header_line_count=1,\n",
    "    sep=','    \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.catalog.create_csv_table(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    database=None, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    path='s3://{}/data/transformed/'.format(bucket), \n",
    "    table=\"reviews\",    \n",
    "    columns_types={\n",
    "        'sentiment': 'int',        \n",
    "        'review_body': 'string',\n",
    "        'product_category': 'string'      \n",
    "    },\n",
    "    mode='overwrite',\n",
    "    skip_header_line_count=1,\n",
    "    sep=','\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the registered table in the AWS Glue Catalog.\n",
    "\n",
    "**Instructions**:\n",
    "- open the link\n",
    "- on the left side panel notice that you are in the AWS Glue -> Data Catalog -> Databases -> Tables\n",
    "- check that you can see the table `reviews` from the database `dsoaws_deep_learning` in the list\n",
    "- click on the name of the table\n",
    "- explore the available information about the table (name, database, classification, location, schema etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"top\" href=\"https://console.aws.amazon.com/glue/home?region={}#\">AWS Glue Catalog</a></b>'.format(region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the table shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wr.catalog.table(database='dsoaws_deep_learning',\n",
    "                         table='reviews')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-2.2.'></a>\n",
    "### 2.2. Create default S3 bucket for Amazon Athena\n",
    "\n",
    "Amazon Athena requires this S3 bucket to store temporary query results and improve performance of subsequent queries.\n",
    "\n",
    "The contents of this bucket are mostly binary and human-unreadable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket name\n",
    "wr.athena.create_athena_bucket()\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# 's3://aws-athena-query-results-ACCOUNT-REGION/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-3.'></a>\n",
    "# 3. Visualize data\n",
    "\n",
    "**Reviews dataset - column descriptions**\n",
    "\n",
    "- `sentiment`: The review's sentiment (-1, 0, 1).\n",
    "- `product_category`: Broad product category that can be used to group reviews (in this case digital videos).\n",
    "- `review_body`: The text of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-3.1.'></a>\n",
    "### 3.1. Preparation for data visualization\n",
    "\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Settings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set AWS Glue database and table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change the database and table names - they are used for grading purposes!\n",
    "database_name = 'dsoaws_deep_learning'\n",
    "table_name = 'reviews'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seaborn parameters. You can review seaborn documentation following the [link](https://seaborn.pydata.org/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style = 'seaborn-whitegrid'\n",
    "\n",
    "sns.set(rc={\"font.style\":\"normal\",\n",
    "            \"axes.facecolor\":\"white\",\n",
    "            'grid.color': '.8',\n",
    "            'grid.linestyle': '-',\n",
    "            \"figure.facecolor\":\"white\",\n",
    "            \"figure.titlesize\":20,\n",
    "            \"text.color\":\"black\",\n",
    "            \"xtick.color\":\"black\",\n",
    "            \"ytick.color\":\"black\",\n",
    "            \"axes.labelcolor\":\"black\",\n",
    "            \"axes.grid\":True,\n",
    "            'axes.labelsize':10,\n",
    "            'xtick.labelsize':10,\n",
    "            'font.size':10,\n",
    "            'ytick.labelsize':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper code to display values on barplots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run SQL queries using Amazon Athena**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazon Athena** lets you query data in Amazon S3 using a standard SQL interface. It reflects the databases and tables in the AWS Glue Catalog. You can create interactive queries and perform any data manipulations required for further downstream processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard SQL query can be saved as a string and then passed as a parameter into the Athena query. Run the following cells as an example to count the total number of reviews by sentiment. The SQL query here will take the following form:\n",
    "\n",
    "```sql\n",
    "SELECT column_name, COUNT(column_name) as new_column_name\n",
    "FROM table_name\n",
    "GROUP BY column_name\n",
    "ORDER BY column_name\n",
    "```\n",
    "\n",
    "If you are not familiar with the SQL query statements, you can review some tutorials following the [link](https://www.w3schools.com/sql/default.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-3.2.'></a>\n",
    "### 3.2. How many reviews per sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the SQL statement to find the count of sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_count_by_sentiment = \"\"\"\n",
    "SELECT sentiment, COUNT(sentiment) AS count_sentiment\n",
    "FROM reviews\n",
    "GROUP BY sentiment\n",
    "ORDER BY sentiment\n",
    "\"\"\"\n",
    "\n",
    "print(statement_count_by_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query data in Amazon Athena database cluster using the prepared SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_by_sentiment = wr.athena.read_sql_query(\n",
    "    sql=statement_count_by_sentiment,\n",
    "    database=database_name\n",
    ")\n",
    "\n",
    "print(df_count_by_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the results of the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_by_sentiment.plot(kind='bar', x='sentiment', y='count_sentiment', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-ex-3'></a>\n",
    "### Exercise 3\n",
    "\n",
    "Use Amazon Athena query with the standard SQL statement passed as a parameter, to calculate the total number of reviews per `product_category` in the table ```reviews```.\n",
    "\n",
    "**Instructions**: Pass the SQL statement of the form\n",
    "\n",
    "```sql\n",
    "SELECT category_column, COUNT(column_name) AS new_column_name\n",
    "FROM table_name\n",
    "GROUP BY category_column\n",
    "ORDER BY new_column_name DESC\n",
    "```\n",
    "\n",
    "as a triple quote string into the variable `statement_count_by_category`. Please use the column `sentiment` in the `COUNT` function and give it a new name `count_sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all None\n",
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "statement_count_by_category = \"\"\"\n",
    "SELECT None, COUNT(None) AS None\n",
    "FROM None\n",
    "GROUP BY None \n",
    "ORDER BY None DESC\n",
    "\"\"\"\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "print(statement_count_by_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query data in Amazon Athena database passing the prepared SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_count_by_category = wr.athena.read_sql_query(\n",
    "    sql=statement_count_by_category,\n",
    "    database=database_name\n",
    ")\n",
    "\n",
    "df_count_by_category\n",
    "\n",
    "# EXPECTED OUTPUT\n",
    "# Dresses: 6145\n",
    "# Knits: 4626\n",
    "# Blouses: 2983\n",
    "# Sweaters: 1380\n",
    "# Pants: 1350\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-3.3.'></a>\n",
    "### 3.3. Which product categories are highest rated by average sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the SQL statement to find the average sentiment per product category, showing the results in the descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_avg_by_category = \"\"\"\n",
    "SELECT product_category, AVG(sentiment) AS avg_sentiment\n",
    "FROM {} \n",
    "GROUP BY product_category \n",
    "ORDER BY avg_sentiment DESC\n",
    "\"\"\".format(table_name)\n",
    "\n",
    "print(statement_avg_by_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query data in Amazon Athena database passing the prepared SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_avg_by_category = wr.athena.read_sql_query(\n",
    "    sql=statement_avg_by_category,\n",
    "    database=database_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the query results in the temporary S3 bucket:  `s3://aws-athena-query-results-ACCOUNT-REGION/`\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- check the name of the S3 bucket\n",
    "- briefly check the content of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/buckets/aws-athena-query-results-{}-{}?region={}\">Amazon S3 buckets</a></b>'.format(account_id, region, region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the results of the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_by_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_values_barplot(axs, space):\n",
    "    def _show_on_plot(ax):\n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() + float(space)\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = round(float(p.get_width()),2)\n",
    "            ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_plot(ax)\n",
    "    else:\n",
    "        _show_on_plot(axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "barplot = sns.barplot(\n",
    "    data = df_avg_by_category, \n",
    "    y='product_category',\n",
    "    x='avg_sentiment', \n",
    "    color=\"b\", \n",
    "    saturation=1\n",
    ")\n",
    "\n",
    "# Set the size of the figure\n",
    "sns.set(rc={'figure.figsize':(15.0, 10.0)})\n",
    "    \n",
    "# Set title and x-axis ticks \n",
    "plt.title('Average sentiment by product category')\n",
    "#plt.xticks([-1, 0, 1], ['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "# Helper code to show actual values afters bars \n",
    "show_values_barplot(barplot, 0.1)\n",
    "\n",
    "plt.xlabel(\"Average sentiment\")\n",
    "plt.ylabel(\"Product category\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# Do not change the figure name - it is used for grading purposes!\n",
    "plt.savefig('avg_sentiment_per_category.png', dpi=300)\n",
    "\n",
    "# Show graphic\n",
    "plt.show(barplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload image to S3 bucket\n",
    "sess.upload_data(path='avg_sentiment_per_category.png', bucket=bucket, key_prefix=\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the bucket on the account.\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- click on the S3 bucket name `sagemaker-us-east-1-ACCOUNT`\n",
    "- open the images folder\n",
    "- check the existence of the image `avg_sentiment_per_category.png`\n",
    "- if you click on the image name, you can see the information about the image file. You can also download the file with the command on the top right Object Actions -> Download / Download as\n",
    "<img src=\"images/download_image_file.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"top\" href=\"https://s3.console.aws.amazon.com/s3/home?region={}\">Amazon S3 buckets</a></b>'.format(region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-3.4.'></a>\n",
    "### 3.4. Which product categories have the most reviews?\n",
    "\n",
    "Set the SQL statement to find the count of sentiment per product category, showing the results in the descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_count_by_category_desc = \"\"\"\n",
    "SELECT product_category, COUNT(*) AS count_reviews \n",
    "FROM {}\n",
    "GROUP BY product_category \n",
    "ORDER BY count_reviews DESC\n",
    "\"\"\".format(table_name)\n",
    "\n",
    "print(statement_count_by_category_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query data in Amazon Athena database passing the prepared SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_count_by_category_desc = wr.athena.read_sql_query(\n",
    "    sql=statement_count_by_category_desc,\n",
    "    database=database_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store maximum number of sentiment for the visualization plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentiment = df_count_by_category_desc['count_reviews'].max()\n",
    "print('Highest number of reviews (in a single category): {}'.format(max_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-ex-4'></a>\n",
    "### Exercise 4\n",
    "\n",
    "Use `barplot` function to plot number of reviews per product category.\n",
    "\n",
    "**Instructions**: Use the `barplot` chart example in the previous section, passing the newly defined dataframe `df_count_by_category_desc` with the count of reviews. Here, please put the `product_category` column into the `y` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seaborn barplot\n",
    "barplot = sns.barplot(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    data=None, # Replace None\n",
    "    y=None, # Replace None\n",
    "    x=None, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    color=\"b\",\n",
    "    saturation=1\n",
    ")\n",
    "\n",
    "# Set the size of the figure\n",
    "sns.set(rc={'figure.figsize':(15.0, 10.0)})\n",
    "    \n",
    "# Set title\n",
    "plt.title(\"Number of reviews per product category\")\n",
    "plt.xlabel(\"Number of reviews\")\n",
    "plt.ylabel(\"Product category\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Do not change the figure name - it is used for grading purposes!\n",
    "plt.savefig('num_reviews_per_category.png', dpi=300)\n",
    "\n",
    "# Show the barplot\n",
    "plt.show(barplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload image to S3 bucket\n",
    "sess.upload_data(path='num_reviews_per_category.png', bucket=bucket, key_prefix=\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-3.5.'></a>\n",
    "### 3.5. What is the breakdown of sentiments per product category?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the SQL statement to find the count of sentiment per product category and sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_count_by_category_and_sentiment = \"\"\"\n",
    "SELECT product_category,\n",
    "         sentiment,\n",
    "         COUNT(*) AS count_reviews\n",
    "FROM {}\n",
    "GROUP BY  product_category, sentiment\n",
    "ORDER BY  product_category ASC, sentiment DESC, count_reviews\n",
    "\"\"\".format(table_name)\n",
    "\n",
    "print(statement_count_by_category_and_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query data in Amazon Athena database passing the prepared SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_count_by_category_and_sentiment = wr.athena.read_sql_query(\n",
    "    sql=statement_count_by_category_and_sentiment,\n",
    "    database=database_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for stacked percentage horizontal bar plot showing proportion of sentiments per product category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grouped dataframes by category and by sentiment\n",
    "grouped_category = df_count_by_category_and_sentiment.groupby('product_category')\n",
    "grouped_star = df_count_by_category_and_sentiment.groupby('sentiment')\n",
    "\n",
    "# Create sum of sentiments per star sentiment\n",
    "df_sum = df_count_by_category_and_sentiment.groupby(['sentiment']).sum()\n",
    "\n",
    "# Calculate total number of sentiments\n",
    "total = df_sum['count_reviews'].sum()\n",
    "print('Total number of reviews: {}'.format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary of product categories and array of star rating distribution per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = {}\n",
    "count_reviews_per_star = []\n",
    "i=0\n",
    "\n",
    "for category, sentiments in grouped_category:\n",
    "    count_reviews_per_star = []\n",
    "    for star in sentiments['sentiment']:\n",
    "        count_reviews_per_star.append(sentiments.at[i, 'count_reviews'])\n",
    "        i=i+1;\n",
    "    distribution[category] = count_reviews_per_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build array per star across all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distribution_pct = pd.DataFrame(distribution).transpose().apply(\n",
    "    lambda num_sentiments: num_sentiments/sum(num_sentiments)*100, axis=1\n",
    ")\n",
    "df_distribution_pct.columns=['1', '0', '-1']\n",
    "df_distribution_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**\n",
    "\n",
    "Plot the distributions of sentiments per product category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df_distribution_pct.index\n",
    "\n",
    "# Plot bars\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "df_distribution_pct.plot(kind=\"barh\", \n",
    "                         stacked=True, \n",
    "                         edgecolor='white',\n",
    "                         width=1.0,\n",
    "                         color=['green', \n",
    "                                'orange', \n",
    "                                'blue'])\n",
    "\n",
    "plt.title(\"Distribution of reviews per sentiment per category\", \n",
    "          fontsize='16')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,1), \n",
    "           loc=\"upper left\",\n",
    "           labels=['Positive', \n",
    "                   'Neutral', \n",
    "                   'Negative'])\n",
    "\n",
    "plt.xlabel(\"% Breakdown of sentiments\", fontsize='14')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Do not change the figure name - it is used for grading purposes!\n",
    "plt.savefig('distribution_sentiment_per_category.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload image to S3 bucket\n",
    "sess.upload_data(path='distribution_sentiment_per_category.png', bucket=bucket, key_prefix=\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c1w1-3.6.'></a>\n",
    "### 3.6. Analyze the distribution of review word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the SQL statement to count the number of the words in each of the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_num_words = \"\"\"\n",
    "    SELECT CARDINALITY(SPLIT(review_body, ' ')) as num_words\n",
    "    FROM {}\n",
    "\"\"\".format(table_name)\n",
    "\n",
    "print(statement_num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query data in Amazon Athena database passing the SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_num_words = wr.athena.read_sql_query(\n",
    "    sql=statement_num_words,\n",
    "    database=database_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out and analyse some descriptive statistics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df_num_words[\"num_words\"].describe(percentiles=[0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the words number per review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_words[\"num_words\"].plot.hist(xticks=[0, 16, 32, 64, 128, 256], bins=100, range=[0, 256]).axvline(\n",
    "    x=summary[\"100%\"], c=\"red\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Words number\", fontsize='14')\n",
    "plt.ylabel(\"Frequency\", fontsize='14')\n",
    "plt.savefig('distribution_num_words_per_review.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload image to S3 bucket\n",
    "sess.upload_data(path='distribution_num_words_per_review.png', bucket=bucket, key_prefix=\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the notebook into S3 bucket for grading purposes.\n",
    "\n",
    "**Note**: you may need to click on \"Save\" button before the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./C1_W1_Assignment.ipynb s3://$bucket/C1_W1_Assignment_Learner.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please go to the main lab window and click on `Submit` button (see the `Finish the lab` section of the instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
